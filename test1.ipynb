{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"bbs-screen bbs-content\" id=\"main-content\"><div class=\"article-metaline\"><span class=\"article-meta-tag\">作者</span><span class=\"article-meta-value\">vul3nn (盛)</span></div><div class=\"article-metaline-right\"><span class=\"article-meta-tag\">看板</span><span class=\"article-meta-value\">Food</span></div><div class=\"article-metaline\"><span class=\"article-meta-tag\">標題</span><span class=\"article-meta-value\">[食記] 新竹東區-玉龍肉圓(原竹蓮肉圓)</span></div><div class=\"article-metaline\"><span class=\"article-meta-tag\">時間</span><span class=\"article-meta-value\">Tue Mar  1 16:15:16 2016</span></div>\n",
      "店名: 玉龍肉圓 (原竹蓮肉圓)\n",
      "食用時間: 104/12\n",
      "地址:  新竹市南大路464號（近新竹國小）\n",
      "電話:  0910-960-776\n",
      "營業時間:  08:00-20:00\n",
      "價格:0-50\n",
      "=============================================================\n",
      "好讀網誌版\n",
      "<a href=\"http://leosheng.tw/wunsylung/\" rel=\"nofollow\" target=\"_blank\">http://leosheng.tw/wunsylung/</a>\n",
      "\n",
      "南大路上的玉龍肉圓，靠近新竹國小，招牌上大大夫妻的照片，頗為醒目\n",
      "看過去是老牌的小吃店，想說新竹老牌小吃店應該比隨意吃好吧，吃看看\n",
      "玉龍肉圓算是竹蓮肉圓的接班店，第二代\n",
      "竹蓮肉圓的原址由哥哥接手，弟弟則來到南大路上開這家玉龍\n",
      "台灣各地不少小吃都是這樣，這難免是分家的關係\n",
      "至於兩家有何差異真的是要吃看看才知道，\"港款丟某剛師傅\"道理就在這\n",
      "新竹的肉圓常見比較多的是紅糟肉圓，應該都是用炸的\n",
      "紅糟肉圓的味道跟中部的肉圓又不甚相同，不管皮跟餡都是\n",
      "跟台北的話嗎… 台北我實在不常吃肉圓，改天再來尋覓一下\n",
      "菜單 MENU\n",
      "一粒20，兼賣羹湯還有骨仔肉湯\n",
      "肉圓個頭不算大，然後醬汁不多，中南部的醬汁多不少!\n",
      "醬汁不多的好處就是，不會泡在醬汁裡，有的醬汁會比較油膩，不愛\n",
      "內餡是很扎實的肉塊，咬勁很夠，然後醃料的味道重，而且放入不少青蔥\n",
      "味道又更重一點，比較沒有其他像是筍乾阿之類的配料，就是很扎實又味道重的內餡皮的\n",
      "話就是Q，軟Q那種，沒有微微酥脆的外皮，但也不會說到麻糬那麼軟\n",
      "比較類似芋圓那種咬感，還不錯\n",
      "魚粳湯–30圓\n",
      "蘿蔔湯配上軟軟的粳，沒說多特別\n",
      "愛吃肉的可以直接選骨仔肉湯，肉有的好咬有的要嚼一下\n",
      "口感當然是比魚粳有趣多拉\n",
      "總結\n",
      "竹蓮肉圓兒子的店\n",
      "傳統的Q皮紅糟肉圓\n",
      "價錢還行\n",
      "\n",
      "--\n",
      "<span class=\"f2\">※ 發信站: 批踢踢實業坊(ptt.cc), 來自: 118.160.101.18\n",
      "</span><span class=\"f2\">※ 文章網址: <a href=\"https://www.ptt.cc/bbs/Food/M.1456820119.A.ACB.html\" rel=\"nofollow\" target=\"_blank\">https://www.ptt.cc/bbs/Food/M.1456820119.A.ACB.html</a>\n",
      "</span><span class=\"f2\">※ </span><span class=\"f2 hl\">vul3nn</span><span class=\"f2\">:轉錄至看板 Hsinchu</span>                                       03/01 16:16\n",
      "<div class=\"push\"><span class=\"hl push-tag\">推 </span><span class=\"f3 hl push-userid\">antennaboy</span><span class=\"f3 push-content\">: 借問市場內那家也是哥哥嗎?</span><span class=\"push-ipdatetime\"> 03/02 23:19\n",
      "</span></div></div>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "res=requests.get('https://www.ptt.cc/bbs/Food/M.1456820119.A.ACB.html',verify=False)\n",
    "soup=BeautifulSoup(res.text)\n",
    "practice=soup.select('#main-content')\n",
    "print (practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[食記] 台北/多麼Cafe+/早午餐、插座、不限時\n",
      "uni929 (呱呱)\n",
      "Sat Mar  5 13:10:07 2016\n",
      "\n",
      "\n",
      "   餐廳名稱：多麼Cafe'+\n",
      "   消費時間：2016年/3月\n",
      "   地址：台北市大安區安和路217巷16號\n",
      "   電話：02-2733-0009\n",
      "   營業時間：週一 ～ 週四：11:30 - 23:00\n",
      "             週五：11:30 - 1:00\n",
      "             週六：10:30 - 1:00\n",
      "             週日：10:30 - 23:00\n",
      "   每人平均價位：450\n",
      "   用餐時間：無限制\n",
      "   插頭：每個位置都有，免費\n",
      "   官網：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "res=requests.get('https://www.ptt.cc/bbs/Food/M.1457154609.A.2A3.html',verify=False)\n",
    "soup=BeautifulSoup(res.text)\n",
    "title=soup.select(\".article-meta-value\")[2].text   # id='#' and class='.'\n",
    "article=soup.select(\".article-meta-value\")[0].text\n",
    "times=soup.select('.article-meta-value')[3].text\n",
    "content=soup.select('#main-content')[0].contents[4]\n",
    "\n",
    "print (title)\n",
    "print (article)\n",
    "print(times)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def change_page():\n",
    "    for i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3f3cb9f3e65f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mindexCounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mboardCounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mcrawl_in_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboardCounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexCounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m#while True:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f3cb9f3e65f>\u001b[0m in \u001b[0;36mcrawl_in_page\u001b[1;34m(board, indexNum)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcrawl_in_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mcon_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f3cb9f3e65f>\u001b[0m in \u001b[0;36mlink_list\u001b[1;34m(board, indexNum)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlink_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhttpReq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.r-ent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mlink_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.ptt.cc'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3f3cb9f3e65f>\u001b[0m in \u001b[0;36mhttpReq\u001b[1;34m(board, indexNum)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mindex_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.ptt.cc/bbs/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mboard\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/index'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.html'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mindex_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user1\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[0mbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import requests, datetime, time, json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def httpReq(board, indexNum):\n",
    "    index_url = 'https://www.ptt.cc/bbs/' + board + '/index' + str(indexNum) + '.html'\n",
    "    index_res = requests.get(index_url)\n",
    "    return BeautifulSoup(index_res.text, 'html5lib')\n",
    "\n",
    "def link_list(board, indexNum):\n",
    "    link_list = []\n",
    "    for link in httpReq(board, indexNum).select('.r-ent'):\n",
    "        link_list.append('https://www.ptt.cc' + link.select('a')[0]['href'])\n",
    "    return link_list\n",
    "\n",
    "def grap_push_info(soup):\n",
    "    pushInfo_list = []\n",
    "    for i in soup.select('.push'):\n",
    "        if len(i.select('.push-ipdatetime')[0].string.strip()) > 11:\n",
    "            continue\n",
    "        pushInfo_list.append(\n",
    "                              # date (e.g. '02/18')\n",
    "                             [i.select('.push-ipdatetime')[0].string.strip(), \n",
    "                              # userid (e.g. 'comdan66')\n",
    "                              i.select('.push-userid')[0].string.strip(), \n",
    "                              # push content\n",
    "                              i.select('.push-content')[0].string[1:].strip()]\n",
    "        )\n",
    "    return pushInfo_list\n",
    "\n",
    "def grap_orig_post(soup):\n",
    "    return (\n",
    "        # date (e.g. 'Mon Aug 29 14:32:25 2005')\n",
    "        soup.select('.article-meta-value')[3].text.strip() +'``!@'+\n",
    "        # title\n",
    "        soup.select('.article-meta-value')[2].text.strip() +'``!@'+\n",
    "        # userid (e.g. 'skyboy')\n",
    "        soup.select('.article-meta-value')[0].text.split('(')[0].strip() +'``!@'+                   \n",
    "        # content\n",
    "        soup.select('#main-content')[0].contents[4].strip()\n",
    "    ).split('``!@')\n",
    "\n",
    "def get_year(soup, push_m, push_d):\n",
    "    m_dict = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, \n",
    "              'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "    \n",
    "    post_y = int(soup.select('.article-meta-value')[3].text.strip()[-4:])\n",
    "    post_m = m_dict[soup.select('.article-meta-value')[3].text.strip()[4:7].lower()]\n",
    "    \n",
    "    if push_m < post_m:\n",
    "        return str(post_y+1)\n",
    "    else:\n",
    "        return str(post_y)\n",
    "\n",
    "def crawl_in_page(board, indexNum):\n",
    "    for link in link_list(board, indexNum):\n",
    "        try:\n",
    "            con_res = requests.get(link)\n",
    "            con_soup = BeautifulSoup(con_res.text, 'html5lib')\n",
    "        except:\n",
    "            counter = 1\n",
    "            while counter <= 3:\n",
    "                print('Retry after 2 sec...')\n",
    "                time.sleep(2)\n",
    "                con_res = requests.get(link)\n",
    "                con_soup = BeautifulSoup(con_res.text, 'html5lib')\n",
    "                counter += 1\n",
    "        try:\n",
    "            # crawl main content\n",
    "            ptt_data.append({\n",
    "                'date'   : grap_orig_post(con_soup)[0],\n",
    "                'title'  : grap_orig_post(con_soup)[1],\n",
    "                'userid' : grap_orig_post(con_soup)[2],\n",
    "                'content': grap_orig_post(con_soup)[3],\n",
    "                'url'    : con_res.url,\n",
    "                'is_orig_post': True\n",
    "            })\n",
    "\n",
    "            # crawl push content\n",
    "            for i in grap_push_info(con_soup):\n",
    "\n",
    "                ptt_data.append({\n",
    "                    'date'   : get_year(con_soup, int(i[0][0:2]), int(i[0][3:5])) + '/' + i[0],\n",
    "                    'title'  : grap_orig_post(con_soup)[1],\n",
    "                    'userid' : i[1],\n",
    "                    'content': i[2],\n",
    "                    'url'    : con_res.url,\n",
    "                    'is_orig_post': False\n",
    "                })\n",
    "\n",
    "            with open('ptt_data.json', 'w') as outfile:\n",
    "                json.dump(ptt_data, outfile)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "\n",
    "ptt_data = []\n",
    "board = ['Yunlin', 'Lifeismoney']\n",
    "indexCounter = 1\n",
    "boardCounter = 0\n",
    "crawl_in_page(board[boardCounter], indexCounter)\n",
    "\n",
    "#while True:\n",
    "#    try:\n",
    "#        crawl_in_page(board[boardCounter], indexCounter)\n",
    "#    except:\n",
    "#        crawl_in_page(board[boardCounter+1], indexCounter)\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aug 29 14:32:25 2005', 'skyboy', ':)歡迎光臨', 'https://www.ptt.cc/bbs/Yunlin/M.1125296921.A.E57.html', 'Yunlin', '1']\n",
      "['Aug 29 22:17:34 2005', 'smalloswald', '我來遲了', 'https://www.ptt.cc/bbs/Yunlin/M.1125324964.A.690.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 30 22:29:00 2005', 'skyboy', '[公告] 萬年版龜 v1.0', 'https://www.ptt.cc/bbs/Yunlin/M.1125411883.A.A4A.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 13:02:55 2005', 'skyboy', '[公告] 版友自介格式', 'https://www.ptt.cc/bbs/Yunlin/M.1125463637.A.A26.html', 'Yunlin', '1']\n",
      "['Aug 31 13:16:10 2005', 'arthurpu', '[自介]恭喜開版', 'https://www.ptt.cc/bbs/Yunlin/M.1125464786.A.D87.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 13:20:44 2005', 'askmaymay', '[自介] askmaymay', 'https://www.ptt.cc/bbs/Yunlin/M.1125465514.A.0F7.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 14:58:32 2005', 'kikowww16', '[自介] kikowww16', 'https://www.ptt.cc/bbs/Yunlin/M.1125471011.A.276.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 15:25:50 2005', 'lexus33', '[自介]lexus33', 'https://www.ptt.cc/bbs/Yunlin/M.1125471667.A.C2A.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 16:36:17 2005', 'hanews', '[自介]hanews', 'https://www.ptt.cc/bbs/Yunlin/M.1125475140.A.BCC.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 16:17:07 2005', 'fdps0808', '[自介] fdps0808', 'https://www.ptt.cc/bbs/Yunlin/M.1125475902.A.64B.html', 'Yunlin', '1']\n",
      "['Aug 31 16:45:59 2005', 'peiwenShi', '[自介] peiwenShi', 'https://www.ptt.cc/bbs/Yunlin/M.1125477794.A.011.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 17:19:50 2005', 'hungry', '[自介]', 'https://www.ptt.cc/bbs/Yunlin/M.1125479897.A.081.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 18:12:33 2005', 'cookiebear', '[自介] 在台北混很久的雲林人', 'https://www.ptt.cc/bbs/Yunlin/M.1125482836.A.489.html', 'Yunlin', '1']\n",
      "['Aug 31 18:25:17 2005', 'IZXNHSO', '[自介] IZXNHSO', 'https://www.ptt.cc/bbs/Yunlin/M.1125483282.A.608.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 19:33:30 2005', 't010081', '[自介] t010081 阿宏', 'https://www.ptt.cc/bbs/Yunlin/M.1125487352.A.491.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 20:19:29 2005', 'yl871015', '[自介] YL871015', 'https://www.ptt.cc/bbs/Yunlin/M.1125490493.A.91F.html', 'Yunlin', '1']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Aug 31 22:12:26 2005', 'ymam', '[自介] YMAM', 'https://www.ptt.cc/bbs/Yunlin/M.1125497333.A.D2D.html', 'Yunlin', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\user1\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py:768: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5bdb9b632595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m         print((crawl_timestamp(record) +'``'+\n\u001b[0;32m     59\u001b[0m                \u001b[0mcrawl_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'``'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                \u001b[0mboard\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'``'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m               ).split('``'))\n",
      "\u001b[1;32m<ipython-input-6-5bdb9b632595>\u001b[0m in \u001b[0;36mcrawl_timestamp\u001b[1;34m(record)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mts_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mts_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mts_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.article-meta-value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'：'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_indexPage(board, indexNum):\n",
    "    retry_counter = 1\n",
    "    while retry_counter <= 3:\n",
    "        index_url = 'https://www.ptt.cc/bbs/' + board + '/index' + str(indexNum) + '.html'\n",
    "        try:\n",
    "            return requests.get(index_url, verify=False)\n",
    "        except KeyboardInterrupt:\n",
    "            print('Interupted by operator.')\n",
    "            break\n",
    "        except:\n",
    "            print('Retry after 2 sec ...')\n",
    "            time.sleep(2)\n",
    "            return requests.get(index_url, verify=False)\n",
    "        retry_counter += 1\n",
    "    return '1'\n",
    "\n",
    "def crawl_data(record):\n",
    "    try:\n",
    "        return (record.select('.author')[0].text.strip() + '``' +\n",
    "                record.select('a')[0].text.strip() + '``' +\n",
    "                'https://www.ptt.cc' + record.select('a')[0]['href'])\n",
    "    except IndexError:\n",
    "        return (record.select('.title')[0].text.strip() + '``'\n",
    "                + 'None')\n",
    "\n",
    "def crawl_timestamp(record):\n",
    "    ts_url = 'https://www.ptt.cc' + record.select('a')[0]['href']\n",
    "    try:\n",
    "        ts_res = requests.get(ts_url, verify=False)\n",
    "    except IndexError:\n",
    "        print('Retry after 2 sec ...')\n",
    "        time.sleep(2)\n",
    "        ts_res = requests.get(ts_url, verify=False)\n",
    "    ts_soup = BeautifulSoup(ts_res.text, 'lxml')\n",
    "    return ts_soup.select('.article-meta-value')[3].text[4:].replace('：',':').strip()\n",
    "\n",
    "\n",
    "\n",
    "indexNum = 1\n",
    "while indexNum <= 1:\n",
    "#while True:\n",
    "    try:\n",
    "        board = 'Yunlin'\n",
    "        soup = BeautifulSoup(get_indexPage(board, indexNum).text, 'lxml')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for record in soup.select('.r-ent'):\n",
    "        try:\n",
    "            crawl_timestamp(record)\n",
    "        except:\n",
    "            continue\n",
    "        print((crawl_timestamp(record) +'``'+\n",
    "               crawl_data(record) + '``' +\n",
    "               board + '``' +\n",
    "               str(indexNum)\n",
    "              ).split('``'))\n",
    "\n",
    "    indexNum += 1\n",
    "\n",
    "print('Nothing More...')\n",
    "\n",
    "#datetime.strptime(crawl_timestamp(record), '%b %d %H:%M:%S %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: '_Helper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e1e59970dbed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBeautifulSoup\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mhelp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: '_Helper'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
